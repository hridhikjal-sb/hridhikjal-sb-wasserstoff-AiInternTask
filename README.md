# llm
# ðŸ¤– RAG Chatbot using LangChain, Gemini & Streamlit

This project is a Retrieval-Augmented Generation (RAG) chatbot built using LangChain, Google Gemini (via LangChain's GoogleGenerativeAI integration), and Streamlit. It supports document upload (PDF, DOCX, TXT) and web URL scraping for context-aware Q&A.

---

Features

 Upload multiple documents (`.pdf`, `.docx`, `.txt`)
 Scrape and load content from URLs
 Vector storage using Chroma DB
 Context-aware Q&A using Gemini 1.5 Flash
Modular code split into multiple files
 Simple and intuitive Streamlit interface

---

File Structure

â”œâ”€â”€ app.py # Streamlit frontend
â”œâ”€â”€ loader.py # Document loading and web scraping
â”œâ”€â”€ vectorstore.py # Embedding and vector DB setup
â”œâ”€â”€ rag_chain.py # Prompt templates and chain construction
â”œâ”€â”€ utils.py # Helper utilities (cleanup, etc.)
â”œâ”€â”€ .env # Environment variables (API keys)
â”œâ”€â”€ docs/ # Folder for loaded/scraped documents
â”œâ”€â”€ .chroma_db/ # Vector database files
â””â”€â”€ README.md # This file

yaml
Copy
Edit


